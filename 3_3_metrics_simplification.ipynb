{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jr9yWJNLIx6_"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tSDf1n7iIJo_"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sets(sets):\n",
    "  merged = set()\n",
    "  for s in sets:\n",
    "    merged = merged.union(s)\n",
    "  return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvcgTTzMtJre"
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXTS = ['text', 'proofreading', 'lex', 'connectives', 'expressions', 'sentence_splitter', 'nominalizations', 'verbs', 'sentence_reorganizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1716393383660,
     "user": {
      "displayName": "Marco Russodivito",
      "userId": "05013084347772678948"
     },
     "user_tz": -120
    },
    "id": "hiRDCeoejAQB",
    "outputId": "cc48f935-f71a-4b58-e4a6-a7d43e084826"
   },
   "outputs": [],
   "source": [
    "metrics_dfs = {TEXT:[] for TEXT in TEXTS}\n",
    "raw_data = {TEXT:[] for TEXT in TEXTS}\n",
    "\n",
    "for TEXT in TEXTS:\n",
    "    metrics_dfs[TEXT] = pd.read_csv(f'./metrics/simplification/{TEXT}_metrics.csv')\n",
    "    raw_data[TEXT] = json.load(open(f'./metrics/simplification/{TEXT}_raw_data.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tokens (con punteg.)</th>\n",
       "      <th>Caratteri</th>\n",
       "      <th>Caratteri (con punt)</th>\n",
       "      <th>Sillabe</th>\n",
       "      <th>Frasi</th>\n",
       "      <th>Types</th>\n",
       "      <th>Lemmi</th>\n",
       "      <th>Tokens per frase</th>\n",
       "      <th>Tokens per paragrafo</th>\n",
       "      <th>Frasi per paragrafo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>15197</td>\n",
       "      <td>17083</td>\n",
       "      <td>83486</td>\n",
       "      <td>85394</td>\n",
       "      <td>34753</td>\n",
       "      <td>589</td>\n",
       "      <td>2897</td>\n",
       "      <td>2272</td>\n",
       "      <td>25.801358</td>\n",
       "      <td>208.178082</td>\n",
       "      <td>8.068493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading</td>\n",
       "      <td>14793</td>\n",
       "      <td>16865</td>\n",
       "      <td>82842</td>\n",
       "      <td>84934</td>\n",
       "      <td>34145</td>\n",
       "      <td>594</td>\n",
       "      <td>2871</td>\n",
       "      <td>2239</td>\n",
       "      <td>24.904040</td>\n",
       "      <td>202.643836</td>\n",
       "      <td>8.136986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex</td>\n",
       "      <td>14599</td>\n",
       "      <td>16648</td>\n",
       "      <td>82194</td>\n",
       "      <td>84263</td>\n",
       "      <td>33780</td>\n",
       "      <td>585</td>\n",
       "      <td>2847</td>\n",
       "      <td>2222</td>\n",
       "      <td>24.955556</td>\n",
       "      <td>199.986301</td>\n",
       "      <td>8.013699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives</td>\n",
       "      <td>14415</td>\n",
       "      <td>16459</td>\n",
       "      <td>81333</td>\n",
       "      <td>83397</td>\n",
       "      <td>33412</td>\n",
       "      <td>587</td>\n",
       "      <td>2840</td>\n",
       "      <td>2212</td>\n",
       "      <td>24.557070</td>\n",
       "      <td>197.465753</td>\n",
       "      <td>8.041096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions</td>\n",
       "      <td>14025</td>\n",
       "      <td>16040</td>\n",
       "      <td>78924</td>\n",
       "      <td>80959</td>\n",
       "      <td>32411</td>\n",
       "      <td>586</td>\n",
       "      <td>2767</td>\n",
       "      <td>2159</td>\n",
       "      <td>23.933447</td>\n",
       "      <td>192.123288</td>\n",
       "      <td>8.027397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter</td>\n",
       "      <td>14243</td>\n",
       "      <td>16322</td>\n",
       "      <td>80837</td>\n",
       "      <td>82936</td>\n",
       "      <td>33153</td>\n",
       "      <td>765</td>\n",
       "      <td>2801</td>\n",
       "      <td>2177</td>\n",
       "      <td>18.618301</td>\n",
       "      <td>195.109589</td>\n",
       "      <td>10.479452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations</td>\n",
       "      <td>14130</td>\n",
       "      <td>16204</td>\n",
       "      <td>80126</td>\n",
       "      <td>82220</td>\n",
       "      <td>32906</td>\n",
       "      <td>765</td>\n",
       "      <td>2825</td>\n",
       "      <td>2187</td>\n",
       "      <td>18.470588</td>\n",
       "      <td>193.561644</td>\n",
       "      <td>10.479452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs</td>\n",
       "      <td>14162</td>\n",
       "      <td>16237</td>\n",
       "      <td>80214</td>\n",
       "      <td>82309</td>\n",
       "      <td>32931</td>\n",
       "      <td>784</td>\n",
       "      <td>2843</td>\n",
       "      <td>2192</td>\n",
       "      <td>18.063776</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>10.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer</td>\n",
       "      <td>14229</td>\n",
       "      <td>16289</td>\n",
       "      <td>80861</td>\n",
       "      <td>82941</td>\n",
       "      <td>33140</td>\n",
       "      <td>787</td>\n",
       "      <td>2843</td>\n",
       "      <td>2196</td>\n",
       "      <td>18.080051</td>\n",
       "      <td>194.917808</td>\n",
       "      <td>10.780822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Corpus  Tokens  Tokens (con punteg.)  Caratteri  \\\n",
       "0                  text   15197                 17083      83486   \n",
       "1          proofreading   14793                 16865      82842   \n",
       "2                   lex   14599                 16648      82194   \n",
       "3           connectives   14415                 16459      81333   \n",
       "4           expressions   14025                 16040      78924   \n",
       "5     sentence_splitter   14243                 16322      80837   \n",
       "6       nominalizations   14130                 16204      80126   \n",
       "7                 verbs   14162                 16237      80214   \n",
       "8  sentence_reorganizer   14229                 16289      80861   \n",
       "\n",
       "   Caratteri (con punt)  Sillabe  Frasi  Types  Lemmi  Tokens per frase  \\\n",
       "0                 85394    34753    589   2897   2272         25.801358   \n",
       "1                 84934    34145    594   2871   2239         24.904040   \n",
       "2                 84263    33780    585   2847   2222         24.955556   \n",
       "3                 83397    33412    587   2840   2212         24.557070   \n",
       "4                 80959    32411    586   2767   2159         23.933447   \n",
       "5                 82936    33153    765   2801   2177         18.618301   \n",
       "6                 82220    32906    765   2825   2187         18.470588   \n",
       "7                 82309    32931    784   2843   2192         18.063776   \n",
       "8                 82941    33140    787   2843   2196         18.080051   \n",
       "\n",
       "   Tokens per paragrafo  Frasi per paragrafo  \n",
       "0            208.178082             8.068493  \n",
       "1            202.643836             8.136986  \n",
       "2            199.986301             8.013699  \n",
       "3            197.465753             8.041096  \n",
       "4            192.123288             8.027397  \n",
       "5            195.109589            10.479452  \n",
       "6            193.561644            10.479452  \n",
       "7            194.000000            10.739726  \n",
       "8            194.917808            10.780822  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':               TEXT,\n",
    "    'Tokens':               df['n_tokens'].sum(),\n",
    "    'Tokens (con punteg.)': df['n_tokens_all'].sum(),\n",
    "    'Caratteri':            df['n_chars'].sum(),\n",
    "    'Caratteri (con punt)': df['n_chars_all'].sum(),\n",
    "    'Sillabe':              df['n_syllables'].sum(),\n",
    "    'Frasi':                df['n_sentences'].sum(),\n",
    "    'Types':                len(merge_sets([set(j['tokens']) for j in raw_data[TEXT]])),\n",
    "    'Lemmi':                len(merge_sets([set(j['lemmas']) for j in raw_data[TEXT]])),\n",
    "    'Tokens per frase':     df['n_tokens'].sum() / df['n_sentences'].sum(),\n",
    "    'Tokens per paragrafo': df['n_tokens'].sum() / df.shape[0],\n",
    "    'Frasi per paragrafo':  df['n_sentences'].sum() / df.shape[0],\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Altro</th>\n",
       "      <th>Nomi</th>\n",
       "      <th>Verbi</th>\n",
       "      <th>Numeri</th>\n",
       "      <th>Simboli</th>\n",
       "      <th>Avverbi</th>\n",
       "      <th>Articoli</th>\n",
       "      <th>Pronomi</th>\n",
       "      <th>Particelle</th>\n",
       "      <th>Agettivi</th>\n",
       "      <th>Preposizioni</th>\n",
       "      <th>Nomi propri</th>\n",
       "      <th>Punteggiatura</th>\n",
       "      <th>Interiezioni</th>\n",
       "      <th>Cong. coord.</th>\n",
       "      <th>Cong. sub.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>20</td>\n",
       "      <td>4262</td>\n",
       "      <td>1523</td>\n",
       "      <td>618</td>\n",
       "      <td>15</td>\n",
       "      <td>286</td>\n",
       "      <td>1339</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>1342</td>\n",
       "      <td>3349</td>\n",
       "      <td>913</td>\n",
       "      <td>1860</td>\n",
       "      <td>0</td>\n",
       "      <td>455</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading</td>\n",
       "      <td>26</td>\n",
       "      <td>4223</td>\n",
       "      <td>1530</td>\n",
       "      <td>625</td>\n",
       "      <td>10</td>\n",
       "      <td>291</td>\n",
       "      <td>1329</td>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>1331</td>\n",
       "      <td>3321</td>\n",
       "      <td>924</td>\n",
       "      <td>2062</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex</td>\n",
       "      <td>27</td>\n",
       "      <td>4113</td>\n",
       "      <td>1528</td>\n",
       "      <td>567</td>\n",
       "      <td>10</td>\n",
       "      <td>291</td>\n",
       "      <td>1328</td>\n",
       "      <td>277</td>\n",
       "      <td>1</td>\n",
       "      <td>1318</td>\n",
       "      <td>3304</td>\n",
       "      <td>927</td>\n",
       "      <td>2043</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives</td>\n",
       "      <td>27</td>\n",
       "      <td>4017</td>\n",
       "      <td>1553</td>\n",
       "      <td>560</td>\n",
       "      <td>8</td>\n",
       "      <td>289</td>\n",
       "      <td>1381</td>\n",
       "      <td>273</td>\n",
       "      <td>1</td>\n",
       "      <td>1307</td>\n",
       "      <td>3168</td>\n",
       "      <td>916</td>\n",
       "      <td>2039</td>\n",
       "      <td>0</td>\n",
       "      <td>458</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions</td>\n",
       "      <td>26</td>\n",
       "      <td>3912</td>\n",
       "      <td>1531</td>\n",
       "      <td>559</td>\n",
       "      <td>8</td>\n",
       "      <td>258</td>\n",
       "      <td>1373</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "      <td>1244</td>\n",
       "      <td>3036</td>\n",
       "      <td>914</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>457</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter</td>\n",
       "      <td>24</td>\n",
       "      <td>4001</td>\n",
       "      <td>1674</td>\n",
       "      <td>557</td>\n",
       "      <td>12</td>\n",
       "      <td>288</td>\n",
       "      <td>1462</td>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>1252</td>\n",
       "      <td>3001</td>\n",
       "      <td>906</td>\n",
       "      <td>2074</td>\n",
       "      <td>0</td>\n",
       "      <td>407</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations</td>\n",
       "      <td>24</td>\n",
       "      <td>3853</td>\n",
       "      <td>1823</td>\n",
       "      <td>557</td>\n",
       "      <td>12</td>\n",
       "      <td>293</td>\n",
       "      <td>1474</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>1237</td>\n",
       "      <td>2894</td>\n",
       "      <td>898</td>\n",
       "      <td>2069</td>\n",
       "      <td>0</td>\n",
       "      <td>407</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs</td>\n",
       "      <td>23</td>\n",
       "      <td>3893</td>\n",
       "      <td>1738</td>\n",
       "      <td>559</td>\n",
       "      <td>12</td>\n",
       "      <td>290</td>\n",
       "      <td>1545</td>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>1230</td>\n",
       "      <td>2859</td>\n",
       "      <td>908</td>\n",
       "      <td>2070</td>\n",
       "      <td>0</td>\n",
       "      <td>407</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer</td>\n",
       "      <td>19</td>\n",
       "      <td>3929</td>\n",
       "      <td>1755</td>\n",
       "      <td>551</td>\n",
       "      <td>12</td>\n",
       "      <td>293</td>\n",
       "      <td>1581</td>\n",
       "      <td>267</td>\n",
       "      <td>1</td>\n",
       "      <td>1229</td>\n",
       "      <td>2866</td>\n",
       "      <td>915</td>\n",
       "      <td>2055</td>\n",
       "      <td>0</td>\n",
       "      <td>405</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Corpus  Altro  Nomi  Verbi  Numeri  Simboli  Avverbi  \\\n",
       "0                  text     20  4262   1523     618       15      286   \n",
       "1          proofreading     26  4223   1530     625       10      291   \n",
       "2                   lex     27  4113   1528     567       10      291   \n",
       "3           connectives     27  4017   1553     560        8      289   \n",
       "4           expressions     26  3912   1531     559        8      258   \n",
       "5     sentence_splitter     24  4001   1674     557       12      288   \n",
       "6       nominalizations     24  3853   1823     557       12      293   \n",
       "7                 verbs     23  3893   1738     559       12      290   \n",
       "8  sentence_reorganizer     19  3929   1755     551       12      293   \n",
       "\n",
       "   Articoli  Pronomi  Particelle  Agettivi  Preposizioni  Nomi propri  \\\n",
       "0      1339      276           0      1342          3349          913   \n",
       "1      1329      276           1      1331          3321          924   \n",
       "2      1328      277           1      1318          3304          927   \n",
       "3      1381      273           1      1307          3168          916   \n",
       "4      1373      248           1      1244          3036          914   \n",
       "5      1462      243           1      1252          3001          906   \n",
       "6      1474      241           1      1237          2894          898   \n",
       "7      1545      279           1      1230          2859          908   \n",
       "8      1581      267           1      1229          2866          915   \n",
       "\n",
       "   Punteggiatura  Interiezioni  Cong. coord.  Cong. sub.  \n",
       "0           1860             0           455         101  \n",
       "1           2062             0           461         101  \n",
       "2           2043             0           461         101  \n",
       "3           2039             0           458         112  \n",
       "4           2010             0           457         114  \n",
       "5           2074             0           407         108  \n",
       "6           2069             0           407         110  \n",
       "7           2070             0           407         114  \n",
       "8           2055             0           405         114  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':        TEXT,\n",
    "    'Altro':         df['n_other'].sum(),\n",
    "    'Nomi':          df['n_nouns'].sum(),\n",
    "    'Verbi':         df['n_verbs'].sum(),\n",
    "    'Numeri':        df['n_number'].sum(),\n",
    "    'Simboli':       df['n_symbols'].sum(),\n",
    "    'Avverbi':       df['n_adverbs'].sum(),\n",
    "    'Articoli':      df['n_articles'].sum(),\n",
    "    'Pronomi':       df['n_pronouns'].sum(),\n",
    "    'Particelle':    df['n_particles'].sum(),\n",
    "    'Agettivi':      df['n_adjectives'].sum(),\n",
    "    'Preposizioni':  df['n_prepositions'].sum(),\n",
    "    'Nomi propri':   df['n_proper_nouns'].sum(),\n",
    "    'Punteggiatura': df['n_punctuations'].sum(),\n",
    "    'Interiezioni':  df['n_interjections'].sum(),\n",
    "    'Cong. coord.':  df['n_coordinating_conjunctions'].sum(),\n",
    "    'Cong. sub.':    df['n_subordinating_conjunctions'].sum(),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Altro</th>\n",
       "      <th>Nomi</th>\n",
       "      <th>Verbi</th>\n",
       "      <th>Numeri</th>\n",
       "      <th>Simboli</th>\n",
       "      <th>Avverbi</th>\n",
       "      <th>Articoli</th>\n",
       "      <th>Pronomi</th>\n",
       "      <th>Particelle</th>\n",
       "      <th>Agettivi</th>\n",
       "      <th>Preposizioni</th>\n",
       "      <th>Nomi propri</th>\n",
       "      <th>Punteggiatura</th>\n",
       "      <th>Interiezioni</th>\n",
       "      <th>Cong. coordinati</th>\n",
       "      <th>Cong. subordiante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>0.09</td>\n",
       "      <td>24.54</td>\n",
       "      <td>10.04</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.80</td>\n",
       "      <td>8.52</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.82</td>\n",
       "      <td>19.24</td>\n",
       "      <td>5.39</td>\n",
       "      <td>10.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading</td>\n",
       "      <td>0.15</td>\n",
       "      <td>24.49</td>\n",
       "      <td>10.12</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.82</td>\n",
       "      <td>8.56</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.71</td>\n",
       "      <td>19.27</td>\n",
       "      <td>5.50</td>\n",
       "      <td>12.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex</td>\n",
       "      <td>0.15</td>\n",
       "      <td>24.25</td>\n",
       "      <td>10.20</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.84</td>\n",
       "      <td>8.64</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.74</td>\n",
       "      <td>19.40</td>\n",
       "      <td>5.55</td>\n",
       "      <td>12.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives</td>\n",
       "      <td>0.15</td>\n",
       "      <td>23.90</td>\n",
       "      <td>10.43</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.84</td>\n",
       "      <td>9.15</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.79</td>\n",
       "      <td>18.76</td>\n",
       "      <td>5.56</td>\n",
       "      <td>12.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions</td>\n",
       "      <td>0.15</td>\n",
       "      <td>23.90</td>\n",
       "      <td>10.63</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.66</td>\n",
       "      <td>9.29</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.49</td>\n",
       "      <td>18.44</td>\n",
       "      <td>5.69</td>\n",
       "      <td>12.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter</td>\n",
       "      <td>0.14</td>\n",
       "      <td>24.06</td>\n",
       "      <td>11.35</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.83</td>\n",
       "      <td>9.76</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.38</td>\n",
       "      <td>17.78</td>\n",
       "      <td>5.49</td>\n",
       "      <td>12.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations</td>\n",
       "      <td>0.15</td>\n",
       "      <td>23.20</td>\n",
       "      <td>12.54</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.88</td>\n",
       "      <td>9.93</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.32</td>\n",
       "      <td>17.13</td>\n",
       "      <td>5.52</td>\n",
       "      <td>12.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs</td>\n",
       "      <td>0.14</td>\n",
       "      <td>23.41</td>\n",
       "      <td>11.87</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.86</td>\n",
       "      <td>10.53</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.26</td>\n",
       "      <td>16.71</td>\n",
       "      <td>5.54</td>\n",
       "      <td>12.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer</td>\n",
       "      <td>0.12</td>\n",
       "      <td>23.65</td>\n",
       "      <td>11.89</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.88</td>\n",
       "      <td>10.77</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.25</td>\n",
       "      <td>16.77</td>\n",
       "      <td>5.56</td>\n",
       "      <td>12.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Corpus  Altro   Nomi  Verbi  Numeri  Simboli  Avverbi  \\\n",
       "0                  text   0.09  24.54  10.04    2.89     0.09     1.80   \n",
       "1          proofreading   0.15  24.49  10.12    3.00     0.08     1.82   \n",
       "2                   lex   0.15  24.25  10.20    2.79     0.08     1.84   \n",
       "3           connectives   0.15  23.90  10.43    2.80     0.07     1.84   \n",
       "4           expressions   0.15  23.90  10.63    2.88     0.08     1.66   \n",
       "5     sentence_splitter   0.14  24.06  11.35    2.80     0.09     1.83   \n",
       "6       nominalizations   0.15  23.20  12.54    2.82     0.09     1.88   \n",
       "7                 verbs   0.14  23.41  11.87    2.81     0.09     1.86   \n",
       "8  sentence_reorganizer   0.12  23.65  11.89    2.74     0.09     1.88   \n",
       "\n",
       "   Articoli  Pronomi  Particelle  Agettivi  Preposizioni  Nomi propri  \\\n",
       "0      8.52     2.07        0.00      7.82         19.24         5.39   \n",
       "1      8.56     2.06        0.01      7.71         19.27         5.50   \n",
       "2      8.64     2.08        0.01      7.74         19.40         5.55   \n",
       "3      9.15     2.07        0.01      7.79         18.76         5.56   \n",
       "4      9.29     2.00        0.01      7.49         18.44         5.69   \n",
       "5      9.76     1.91        0.01      7.38         17.78         5.49   \n",
       "6      9.93     1.89        0.01      7.32         17.13         5.52   \n",
       "7     10.53     2.26        0.01      7.26         16.71         5.54   \n",
       "8     10.77     2.16        0.01      7.25         16.77         5.56   \n",
       "\n",
       "   Punteggiatura  Interiezioni  Cong. coordinati  Cong. subordiante  \n",
       "0          10.88           0.0              2.69               0.55  \n",
       "1          12.19           0.0              2.78               0.53  \n",
       "2          12.22           0.0              2.82               0.54  \n",
       "3          12.33           0.0              2.83               0.60  \n",
       "4          12.49           0.0              2.89               0.67  \n",
       "5          12.70           0.0              2.49               0.61  \n",
       "6          12.77           0.0              2.51               0.63  \n",
       "7          12.75           0.0              2.50               0.68  \n",
       "8          12.45           0.0              2.48               0.68  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':              TEXT,\n",
    "    'Altro':               round((df['n_other'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Nomi':                round((df['n_nouns'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Verbi':               round((df['n_verbs'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Numeri':              round((df['n_number'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Simboli':             round((df['n_symbols'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Avverbi':             round((df['n_adverbs'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Articoli':            round((df['n_articles'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Pronomi':             round((df['n_pronouns'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Particelle':          round((df['n_particles'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Agettivi':            round((df['n_adjectives'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Preposizioni':        round((df['n_prepositions'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Nomi propri':         round((df['n_proper_nouns'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Punteggiatura':       round((df['n_punctuations'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Interiezioni':        round((df['n_interjections'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Cong. coordinati':    round((df['n_coordinating_conjunctions'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Cong. subordiante':   round((df['n_subordinating_conjunctions'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Verbi attivi</th>\n",
       "      <th>Verbi passivi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>913</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading</td>\n",
       "      <td>914</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex</td>\n",
       "      <td>912</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives</td>\n",
       "      <td>929</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions</td>\n",
       "      <td>905</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter</td>\n",
       "      <td>925</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations</td>\n",
       "      <td>1072</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs</td>\n",
       "      <td>1107</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer</td>\n",
       "      <td>1129</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Corpus  Verbi attivi  Verbi passivi\n",
       "0                  text           913            158\n",
       "1          proofreading           914            160\n",
       "2                   lex           912            160\n",
       "3           connectives           929            164\n",
       "4           expressions           905            157\n",
       "5     sentence_splitter           925            190\n",
       "6       nominalizations          1072            190\n",
       "7                 verbs          1107            150\n",
       "8  sentence_reorganizer          1129            149"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':         TEXT,\n",
    "    'Verbi attivi':   df['n_active_verbs'].sum(),\n",
    "    'Verbi passivi':  df['n_passive_verbs'].sum()\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Verbi attivi</th>\n",
       "      <th>Verbi passivi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>60.36</td>\n",
       "      <td>9.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading</td>\n",
       "      <td>60.50</td>\n",
       "      <td>9.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex</td>\n",
       "      <td>60.42</td>\n",
       "      <td>9.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives</td>\n",
       "      <td>60.62</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions</td>\n",
       "      <td>59.90</td>\n",
       "      <td>9.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter</td>\n",
       "      <td>56.45</td>\n",
       "      <td>10.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations</td>\n",
       "      <td>59.35</td>\n",
       "      <td>9.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs</td>\n",
       "      <td>65.60</td>\n",
       "      <td>7.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer</td>\n",
       "      <td>66.54</td>\n",
       "      <td>6.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Corpus  Verbi attivi  Verbi passivi\n",
       "0                  text         60.36           9.74\n",
       "1          proofreading         60.50           9.89\n",
       "2                   lex         60.42           9.94\n",
       "3           connectives         60.62           9.95\n",
       "4           expressions         59.90           9.23\n",
       "5     sentence_splitter         56.45          10.21\n",
       "6       nominalizations         59.35           9.56\n",
       "7                 verbs         65.60           7.20\n",
       "8  sentence_reorganizer         66.54           6.97"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':         TEXT,\n",
    "    'Verbi attivi':   round((df['n_active_verbs'] / df['n_verbs']).fillna(0).mean() * 100, 2),\n",
    "    'Verbi passivi':  round((df['n_passive_verbs'] / df['n_verbs']).fillna(0).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVdB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>ALL</th>\n",
       "      <th>FO</th>\n",
       "      <th>AU</th>\n",
       "      <th>AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>9566</td>\n",
       "      <td>8190</td>\n",
       "      <td>1373</td>\n",
       "      <td>1355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading</td>\n",
       "      <td>9548</td>\n",
       "      <td>8183</td>\n",
       "      <td>1365</td>\n",
       "      <td>1351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex</td>\n",
       "      <td>9432</td>\n",
       "      <td>8071</td>\n",
       "      <td>1362</td>\n",
       "      <td>1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives</td>\n",
       "      <td>9411</td>\n",
       "      <td>8085</td>\n",
       "      <td>1315</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions</td>\n",
       "      <td>9177</td>\n",
       "      <td>7903</td>\n",
       "      <td>1259</td>\n",
       "      <td>1254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter</td>\n",
       "      <td>9423</td>\n",
       "      <td>8114</td>\n",
       "      <td>1292</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations</td>\n",
       "      <td>9452</td>\n",
       "      <td>8158</td>\n",
       "      <td>1279</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs</td>\n",
       "      <td>9511</td>\n",
       "      <td>8208</td>\n",
       "      <td>1289</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer</td>\n",
       "      <td>9582</td>\n",
       "      <td>8268</td>\n",
       "      <td>1294</td>\n",
       "      <td>1205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Corpus   ALL    FO    AU    AD\n",
       "0                  text  9566  8190  1373  1355\n",
       "1          proofreading  9548  8183  1365  1351\n",
       "2                   lex  9432  8071  1362  1346\n",
       "3           connectives  9411  8085  1315  1306\n",
       "4           expressions  9177  7903  1259  1254\n",
       "5     sentence_splitter  9423  8114  1292  1200\n",
       "6       nominalizations  9452  8158  1279  1200\n",
       "7                 verbs  9511  8208  1289  1200\n",
       "8  sentence_reorganizer  9582  8268  1294  1205"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':   TEXT,\n",
    "    'ALL':      df['n_vdb'].sum(),\n",
    "    'FO':       df['n_vdb_fo'].sum(),\n",
    "    'AU':       df['n_vdb_au'].sum(),\n",
    "    'AD':       df['n_vdb_ad'].sum(),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>ALL</th>\n",
       "      <th>FO</th>\n",
       "      <th>AU</th>\n",
       "      <th>AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>65.31</td>\n",
       "      <td>55.79</td>\n",
       "      <td>9.61</td>\n",
       "      <td>8.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading</td>\n",
       "      <td>66.51</td>\n",
       "      <td>56.84</td>\n",
       "      <td>9.78</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex</td>\n",
       "      <td>66.56</td>\n",
       "      <td>56.80</td>\n",
       "      <td>9.87</td>\n",
       "      <td>8.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives</td>\n",
       "      <td>67.46</td>\n",
       "      <td>57.86</td>\n",
       "      <td>9.62</td>\n",
       "      <td>8.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions</td>\n",
       "      <td>67.78</td>\n",
       "      <td>58.48</td>\n",
       "      <td>9.28</td>\n",
       "      <td>8.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter</td>\n",
       "      <td>68.48</td>\n",
       "      <td>59.01</td>\n",
       "      <td>9.44</td>\n",
       "      <td>8.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations</td>\n",
       "      <td>69.42</td>\n",
       "      <td>60.05</td>\n",
       "      <td>9.37</td>\n",
       "      <td>8.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs</td>\n",
       "      <td>69.89</td>\n",
       "      <td>60.52</td>\n",
       "      <td>9.38</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer</td>\n",
       "      <td>70.03</td>\n",
       "      <td>60.65</td>\n",
       "      <td>9.38</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Corpus    ALL     FO    AU    AD\n",
       "0                  text  65.31  55.79  9.61  8.72\n",
       "1          proofreading  66.51  56.84  9.78  8.90\n",
       "2                   lex  66.56  56.80  9.87  8.98\n",
       "3           connectives  67.46  57.86  9.62  8.86\n",
       "4           expressions  67.78  58.48  9.28  8.64\n",
       "5     sentence_splitter  68.48  59.01  9.44  8.14\n",
       "6       nominalizations  69.42  60.05  9.37  8.27\n",
       "7                 verbs  69.89  60.52  9.38  8.20\n",
       "8  sentence_reorganizer  70.03  60.65  9.38  8.16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus': TEXT,\n",
    "    'ALL':    round((df['n_vdb'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "    'FO':     round((df['n_vdb_fo'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "    'AU':     round((df['n_vdb_au'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "    'AD':     round((df['n_vdb_ad'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>difficult_connectives</th>\n",
       "      <th>latinisms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading</td>\n",
       "      <td>158</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex</td>\n",
       "      <td>158</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Corpus  difficult_connectives  latinisms\n",
       "0                  text                    129          2\n",
       "1          proofreading                    158          2\n",
       "2                   lex                    158          2\n",
       "3           connectives                     29          2\n",
       "4           expressions                     33          2\n",
       "5     sentence_splitter                     37          2\n",
       "6       nominalizations                     36          2\n",
       "7                 verbs                     33          2\n",
       "8  sentence_reorganizer                     33          2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':   TEXT,\n",
    "    'difficult_connectives':  df['n_difficult_connectives'].sum(),\n",
    "    'latinisms':              df['n_latinisms'].sum(),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>unique_difficult_connectives</th>\n",
       "      <th>unique_latinisms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Corpus  unique_difficult_connectives  unique_latinisms\n",
       "0                  text                            51                 1\n",
       "1          proofreading                            66                 1\n",
       "2                   lex                            66                 1\n",
       "3           connectives                            19                 1\n",
       "4           expressions                            22                 1\n",
       "5     sentence_splitter                            23                 1\n",
       "6       nominalizations                            23                 1\n",
       "7                 verbs                            22                 1\n",
       "8  sentence_reorganizer                            22                 1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':   TEXT,\n",
    "    'unique_difficult_connectives': len(merge_sets([set(j['difficult_connectives']) for j in raw_data[TEXT]])),\n",
    "    'unique_latinisms':       len(merge_sets([set(j['latinisms']) for j in raw_data[TEXT]])),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>ttr</th>\n",
       "      <th>gulpease_index</th>\n",
       "      <th>flesch_vacca</th>\n",
       "      <th>lexical_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>68.16</td>\n",
       "      <td>44.83</td>\n",
       "      <td>24.68</td>\n",
       "      <td>49.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading</td>\n",
       "      <td>68.93</td>\n",
       "      <td>44.33</td>\n",
       "      <td>24.79</td>\n",
       "      <td>50.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex</td>\n",
       "      <td>69.08</td>\n",
       "      <td>44.10</td>\n",
       "      <td>24.72</td>\n",
       "      <td>50.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives</td>\n",
       "      <td>69.09</td>\n",
       "      <td>44.31</td>\n",
       "      <td>25.02</td>\n",
       "      <td>50.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions</td>\n",
       "      <td>69.59</td>\n",
       "      <td>45.02</td>\n",
       "      <td>27.95</td>\n",
       "      <td>49.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter</td>\n",
       "      <td>69.90</td>\n",
       "      <td>48.74</td>\n",
       "      <td>33.98</td>\n",
       "      <td>51.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations</td>\n",
       "      <td>70.24</td>\n",
       "      <td>48.82</td>\n",
       "      <td>34.24</td>\n",
       "      <td>51.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs</td>\n",
       "      <td>69.29</td>\n",
       "      <td>49.13</td>\n",
       "      <td>34.87</td>\n",
       "      <td>50.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer</td>\n",
       "      <td>68.75</td>\n",
       "      <td>48.87</td>\n",
       "      <td>34.88</td>\n",
       "      <td>51.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Corpus    ttr  gulpease_index  flesch_vacca  lexical_density\n",
       "0                  text  68.16           44.83         24.68            49.66\n",
       "1          proofreading  68.93           44.33         24.79            50.30\n",
       "2                   lex  69.08           44.10         24.72            50.16\n",
       "3           connectives  69.09           44.31         25.02            50.13\n",
       "4           expressions  69.59           45.02         27.95            49.90\n",
       "5     sentence_splitter  69.90           48.74         33.98            51.12\n",
       "6       nominalizations  70.24           48.82         34.24            51.52\n",
       "7                 verbs  69.29           49.13         34.87            50.88\n",
       "8  sentence_reorganizer  68.75           48.87         34.88            51.01"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':             TEXT,\n",
    "    'ttr':                round(df['ttr'].mean(), 2),\n",
    "    'gulpease_index':     round(df['gulpease'].mean(), 2),\n",
    "    'flesch_vacca':       round(df['flesch_vacca'].mean(), 2),\n",
    "    'lexical_density':    round(df['lexical_density'].mean(), 2)\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original vs proofreading</td>\n",
       "      <td>99.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original vs lex</td>\n",
       "      <td>99.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original vs connectives</td>\n",
       "      <td>99.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original vs expressions</td>\n",
       "      <td>98.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original vs sentence_splitter</td>\n",
       "      <td>98.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original vs nominalizations</td>\n",
       "      <td>98.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original vs verbs</td>\n",
       "      <td>97.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original vs sentence_reorganizer</td>\n",
       "      <td>97.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Corpus  semantic_similarity\n",
       "0          original vs proofreading                99.61\n",
       "1                   original vs lex                99.50\n",
       "2           original vs connectives                99.32\n",
       "3           original vs expressions                98.80\n",
       "4     original vs sentence_splitter                98.46\n",
       "5       original vs nominalizations                98.30\n",
       "6                 original vs verbs                97.98\n",
       "7  original vs sentence_reorganizer                97.88"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  if TEXT == 'text':\n",
    "    continue\n",
    "  d.append({\n",
    "    'Corpus':               f'original vs {TEXT}',\n",
    "    'semantic_similarity':  round(df['semantic_similarity'].mean(), 2)\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>editdistance</th>\n",
       "      <th>added_tokens</th>\n",
       "      <th>added_vdb_tokens</th>\n",
       "      <th>%_added_vdb_tokens</th>\n",
       "      <th>deleted_tokens</th>\n",
       "      <th>deleted_vdb_tokens</th>\n",
       "      <th>%_deleted_vdb_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original vs proofreading</td>\n",
       "      <td>2042</td>\n",
       "      <td>603</td>\n",
       "      <td>244</td>\n",
       "      <td>40.46</td>\n",
       "      <td>812</td>\n",
       "      <td>247</td>\n",
       "      <td>30.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original vs lex</td>\n",
       "      <td>3229</td>\n",
       "      <td>692</td>\n",
       "      <td>278</td>\n",
       "      <td>40.17</td>\n",
       "      <td>1057</td>\n",
       "      <td>375</td>\n",
       "      <td>35.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original vs connectives</td>\n",
       "      <td>5635</td>\n",
       "      <td>928</td>\n",
       "      <td>511</td>\n",
       "      <td>55.06</td>\n",
       "      <td>1410</td>\n",
       "      <td>608</td>\n",
       "      <td>43.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original vs expressions</td>\n",
       "      <td>10881</td>\n",
       "      <td>1364</td>\n",
       "      <td>877</td>\n",
       "      <td>64.30</td>\n",
       "      <td>2072</td>\n",
       "      <td>1088</td>\n",
       "      <td>52.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original vs sentence_splitter</td>\n",
       "      <td>14906</td>\n",
       "      <td>1771</td>\n",
       "      <td>1230</td>\n",
       "      <td>69.45</td>\n",
       "      <td>2306</td>\n",
       "      <td>1202</td>\n",
       "      <td>52.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original vs nominalizations</td>\n",
       "      <td>16423</td>\n",
       "      <td>1948</td>\n",
       "      <td>1374</td>\n",
       "      <td>70.53</td>\n",
       "      <td>2506</td>\n",
       "      <td>1296</td>\n",
       "      <td>51.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original vs verbs</td>\n",
       "      <td>19088</td>\n",
       "      <td>2175</td>\n",
       "      <td>1570</td>\n",
       "      <td>72.18</td>\n",
       "      <td>2765</td>\n",
       "      <td>1501</td>\n",
       "      <td>54.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original vs sentence_reorganizer</td>\n",
       "      <td>20263</td>\n",
       "      <td>2205</td>\n",
       "      <td>1573</td>\n",
       "      <td>71.34</td>\n",
       "      <td>2850</td>\n",
       "      <td>1507</td>\n",
       "      <td>52.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Corpus  editdistance  added_tokens  \\\n",
       "0          original vs proofreading          2042           603   \n",
       "1                   original vs lex          3229           692   \n",
       "2           original vs connectives          5635           928   \n",
       "3           original vs expressions         10881          1364   \n",
       "4     original vs sentence_splitter         14906          1771   \n",
       "5       original vs nominalizations         16423          1948   \n",
       "6                 original vs verbs         19088          2175   \n",
       "7  original vs sentence_reorganizer         20263          2205   \n",
       "\n",
       "   added_vdb_tokens  %_added_vdb_tokens  deleted_tokens  deleted_vdb_tokens  \\\n",
       "0               244               40.46             812                 247   \n",
       "1               278               40.17            1057                 375   \n",
       "2               511               55.06            1410                 608   \n",
       "3               877               64.30            2072                1088   \n",
       "4              1230               69.45            2306                1202   \n",
       "5              1374               70.53            2506                1296   \n",
       "6              1570               72.18            2765                1501   \n",
       "7              1573               71.34            2850                1507   \n",
       "\n",
       "   %_deleted_vdb_tokens  \n",
       "0                 30.42  \n",
       "1                 35.48  \n",
       "2                 43.12  \n",
       "3                 52.51  \n",
       "4                 52.12  \n",
       "5                 51.72  \n",
       "6                 54.29  \n",
       "7                 52.88  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  if TEXT == 'text':\n",
    "    continue\n",
    "  d.append({\n",
    "    'Corpus':                 f'original vs {TEXT}',\n",
    "    'editdistance':           df['editdistance'].sum(),\n",
    "    'added_tokens':           df['n_added_tokens'].sum(),\n",
    "    'added_vdb_tokens':       df['n_added_vdb_tokens'].sum(),\n",
    "    '%_added_vdb_tokens':     round(df['n_added_vdb_tokens'].sum() / df['n_added_tokens'].sum() * 100, 2),\n",
    "    'deleted_tokens':         df['n_deleted_tokens'].sum(),\n",
    "    'deleted_vdb_tokens':     df['n_deleted_vdb_tokens'].sum(),\n",
    "    '%_deleted_vdb_tokens':   round(df['n_deleted_vdb_tokens'].sum() / df['n_deleted_tokens'].sum() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>editdistance</th>\n",
       "      <th>added_tokens</th>\n",
       "      <th>added_vdb_tokens</th>\n",
       "      <th>deleted_tokens</th>\n",
       "      <th>deleted_vdb_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original vs proofreading</td>\n",
       "      <td>2.38</td>\n",
       "      <td>4.57</td>\n",
       "      <td>2.16</td>\n",
       "      <td>5.49</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original vs lex</td>\n",
       "      <td>3.39</td>\n",
       "      <td>5.03</td>\n",
       "      <td>2.33</td>\n",
       "      <td>6.86</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original vs connectives</td>\n",
       "      <td>6.18</td>\n",
       "      <td>6.87</td>\n",
       "      <td>4.13</td>\n",
       "      <td>9.66</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original vs expressions</td>\n",
       "      <td>14.71</td>\n",
       "      <td>12.72</td>\n",
       "      <td>9.12</td>\n",
       "      <td>17.47</td>\n",
       "      <td>10.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original vs sentence_splitter</td>\n",
       "      <td>19.25</td>\n",
       "      <td>15.83</td>\n",
       "      <td>11.83</td>\n",
       "      <td>18.55</td>\n",
       "      <td>10.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original vs nominalizations</td>\n",
       "      <td>21.38</td>\n",
       "      <td>17.50</td>\n",
       "      <td>13.27</td>\n",
       "      <td>20.46</td>\n",
       "      <td>11.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original vs verbs</td>\n",
       "      <td>24.81</td>\n",
       "      <td>19.35</td>\n",
       "      <td>15.03</td>\n",
       "      <td>22.66</td>\n",
       "      <td>13.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original vs sentence_reorganizer</td>\n",
       "      <td>27.20</td>\n",
       "      <td>19.40</td>\n",
       "      <td>14.91</td>\n",
       "      <td>23.26</td>\n",
       "      <td>13.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Corpus  editdistance  added_tokens  \\\n",
       "0          original vs proofreading          2.38          4.57   \n",
       "1                   original vs lex          3.39          5.03   \n",
       "2           original vs connectives          6.18          6.87   \n",
       "3           original vs expressions         14.71         12.72   \n",
       "4     original vs sentence_splitter         19.25         15.83   \n",
       "5       original vs nominalizations         21.38         17.50   \n",
       "6                 original vs verbs         24.81         19.35   \n",
       "7  original vs sentence_reorganizer         27.20         19.40   \n",
       "\n",
       "   added_vdb_tokens  deleted_tokens  deleted_vdb_tokens  \n",
       "0              2.16            5.49                2.04  \n",
       "1              2.33            6.86                2.70  \n",
       "2              4.13            9.66                4.41  \n",
       "3              9.12           17.47               10.23  \n",
       "4             11.83           18.55               10.75  \n",
       "5             13.27           20.46               11.55  \n",
       "6             15.03           22.66               13.41  \n",
       "7             14.91           23.26               13.50  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  if TEXT == 'text':\n",
    "    continue\n",
    "  d.append({\n",
    "    'Corpus':             f'original vs {TEXT}',\n",
    "    'editdistance':       round((df['editdistance'] / pd.concat([metrics_dfs['text']['n_chars'], df['n_chars']], axis=1).max(axis=1)).mean() * 100, 2),\n",
    "    'added_tokens':       round((df['n_added_tokens'] / df['n_tokens']).mean() * 100, 2),\n",
    "    'added_vdb_tokens':   round((df['n_added_vdb_tokens'] /  df['n_tokens']).mean() * 100, 2),\n",
    "    'deleted_tokens':     round((df['n_deleted_tokens'] /  df['n_tokens']).mean() * 100, 2),\n",
    "    'deleted_vdb_tokens': round((df['n_deleted_vdb_tokens'] /  df['n_tokens']).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Types</th>\n",
       "      <th>Frasi</th>\n",
       "      <th>Verbi attivi</th>\n",
       "      <th>ALL</th>\n",
       "      <th>difficult_connectives</th>\n",
       "      <th>gulpease_index</th>\n",
       "      <th>flesch_vacca</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>editdistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>15197</td>\n",
       "      <td>2897</td>\n",
       "      <td>589</td>\n",
       "      <td>60.36</td>\n",
       "      <td>65.31</td>\n",
       "      <td>129</td>\n",
       "      <td>44.83</td>\n",
       "      <td>24.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading</td>\n",
       "      <td>14793</td>\n",
       "      <td>2871</td>\n",
       "      <td>594</td>\n",
       "      <td>60.50</td>\n",
       "      <td>66.51</td>\n",
       "      <td>158</td>\n",
       "      <td>44.33</td>\n",
       "      <td>24.79</td>\n",
       "      <td>99.61</td>\n",
       "      <td>2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex</td>\n",
       "      <td>14599</td>\n",
       "      <td>2847</td>\n",
       "      <td>585</td>\n",
       "      <td>60.42</td>\n",
       "      <td>66.56</td>\n",
       "      <td>158</td>\n",
       "      <td>44.10</td>\n",
       "      <td>24.72</td>\n",
       "      <td>99.50</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives</td>\n",
       "      <td>14415</td>\n",
       "      <td>2840</td>\n",
       "      <td>587</td>\n",
       "      <td>60.62</td>\n",
       "      <td>67.46</td>\n",
       "      <td>29</td>\n",
       "      <td>44.31</td>\n",
       "      <td>25.02</td>\n",
       "      <td>99.32</td>\n",
       "      <td>6.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions</td>\n",
       "      <td>14025</td>\n",
       "      <td>2767</td>\n",
       "      <td>586</td>\n",
       "      <td>59.90</td>\n",
       "      <td>67.78</td>\n",
       "      <td>33</td>\n",
       "      <td>45.02</td>\n",
       "      <td>27.95</td>\n",
       "      <td>98.80</td>\n",
       "      <td>14.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter</td>\n",
       "      <td>14243</td>\n",
       "      <td>2801</td>\n",
       "      <td>765</td>\n",
       "      <td>56.45</td>\n",
       "      <td>68.48</td>\n",
       "      <td>37</td>\n",
       "      <td>48.74</td>\n",
       "      <td>33.98</td>\n",
       "      <td>98.46</td>\n",
       "      <td>19.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations</td>\n",
       "      <td>14130</td>\n",
       "      <td>2825</td>\n",
       "      <td>765</td>\n",
       "      <td>59.35</td>\n",
       "      <td>69.42</td>\n",
       "      <td>36</td>\n",
       "      <td>48.82</td>\n",
       "      <td>34.24</td>\n",
       "      <td>98.30</td>\n",
       "      <td>21.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs</td>\n",
       "      <td>14162</td>\n",
       "      <td>2843</td>\n",
       "      <td>784</td>\n",
       "      <td>65.60</td>\n",
       "      <td>69.89</td>\n",
       "      <td>33</td>\n",
       "      <td>49.13</td>\n",
       "      <td>34.87</td>\n",
       "      <td>97.98</td>\n",
       "      <td>24.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer</td>\n",
       "      <td>14229</td>\n",
       "      <td>2843</td>\n",
       "      <td>787</td>\n",
       "      <td>66.54</td>\n",
       "      <td>70.03</td>\n",
       "      <td>33</td>\n",
       "      <td>48.87</td>\n",
       "      <td>34.88</td>\n",
       "      <td>97.88</td>\n",
       "      <td>27.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Corpus  Tokens  Types  Frasi  Verbi attivi    ALL  \\\n",
       "0                  text   15197   2897    589         60.36  65.31   \n",
       "1          proofreading   14793   2871    594         60.50  66.51   \n",
       "2                   lex   14599   2847    585         60.42  66.56   \n",
       "3           connectives   14415   2840    587         60.62  67.46   \n",
       "4           expressions   14025   2767    586         59.90  67.78   \n",
       "5     sentence_splitter   14243   2801    765         56.45  68.48   \n",
       "6       nominalizations   14130   2825    765         59.35  69.42   \n",
       "7                 verbs   14162   2843    784         65.60  69.89   \n",
       "8  sentence_reorganizer   14229   2843    787         66.54  70.03   \n",
       "\n",
       "   difficult_connectives  gulpease_index  flesch_vacca  semantic_similarity  \\\n",
       "0                    129           44.83         24.68                  NaN   \n",
       "1                    158           44.33         24.79                99.61   \n",
       "2                    158           44.10         24.72                99.50   \n",
       "3                     29           44.31         25.02                99.32   \n",
       "4                     33           45.02         27.95                98.80   \n",
       "5                     37           48.74         33.98                98.46   \n",
       "6                     36           48.82         34.24                98.30   \n",
       "7                     33           49.13         34.87                97.98   \n",
       "8                     33           48.87         34.88                97.88   \n",
       "\n",
       "   editdistance  \n",
       "0           NaN  \n",
       "1          2.38  \n",
       "2          3.39  \n",
       "3          6.18  \n",
       "4         14.71  \n",
       "5         19.25  \n",
       "6         21.38  \n",
       "7         24.81  \n",
       "8         27.20  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d = {        \n",
    "    'Corpus':             f'{TEXT}',\n",
    "    'Tokens':               df['n_tokens'].sum(),\n",
    "    'Types':                len(merge_sets([set(j['tokens']) for j in raw_data[TEXT]])),\n",
    "    'Frasi':                df['n_sentences'].sum(),\n",
    "    'Verbi attivi':   round((df['n_active_verbs'] / df['n_verbs']).fillna(0).mean() * 100, 2),\n",
    "    'ALL':    round((df['n_vdb'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "    'difficult_connectives':  df['n_difficult_connectives'].sum(),\n",
    "    'gulpease_index':     round(df['gulpease'].mean(), 2),\n",
    "    'flesch_vacca':       round(df['flesch_vacca'].mean(), 2)\n",
    "  }\n",
    "  if TEXT != 'text':\n",
    "    d['semantic_similarity'] = round(df['semantic_similarity'].mean(), 2)\n",
    "    d['editdistance'] = round((df['editdistance'] / pd.concat([metrics_dfs['text']['n_chars'], df['n_chars']], axis=1).max(axis=1)).mean() * 100, 2)\n",
    "  all.append(d)\n",
    "  \n",
    "pd.DataFrame(all).head(10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
